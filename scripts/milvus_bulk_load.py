#!/usr/bin/env python3
"""
Load Vector Embeddings into Milvus.

This script creates a Milvus collection and loads the embeddings
generated by generate_embeddings.py.

Prerequisites:
  pip install pymilvus pandas pyarrow boto3

Usage:
  python milvus_bulk_load.py
"""

import io
import time
from typing import List

import boto3
from botocore.client import Config
import pandas as pd

try:
    from pymilvus import (
        connections, utility, Collection, CollectionSchema, 
        FieldSchema, DataType
    )
except ImportError:
    print("Installing pymilvus...")
    import subprocess
    subprocess.check_call(["pip", "install", "pymilvus"])
    from pymilvus import (
        connections, utility, Collection, CollectionSchema, 
        FieldSchema, DataType
    )
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configuration
MILVUS_HOST = os.getenv('MILVUS_HOST', 'localhost')
MILVUS_PORT = os.getenv('MILVUS_PORT', '19530')
COLLECTION_NAME = "orders_vector_index"

MINIO_ENDPOINT = os.getenv('MINIO_URL', 'http://localhost:9100')
MINIO_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY_ID', 'admin')
MINIO_SECRET_KEY = os.getenv('AWS_SECRET_ACCESS_KEY', 'password')
BUCKET_NAME = "lakehouse"
VECTORS_PATH = "gold/milvus_import/vectors.parquet"

# Must match the embedding model dimension
EMBEDDING_DIM = 384


def create_s3_client():
    """Create a boto3 S3 client configured for MinIO."""
    return boto3.client(
        "s3",
        endpoint_url=MINIO_ENDPOINT,
        aws_access_key_id=MINIO_ACCESS_KEY,
        aws_secret_access_key=MINIO_SECRET_KEY,
        config=Config(signature_version="s3v4"),
        region_name="us-east-1",
    )


def wait_for_milvus(max_retries=30, delay=2):
    """Wait for Milvus to be available."""
    print("Waiting for Milvus to be ready...")
    for i in range(max_retries):
        try:
            connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)
            print("✓ Milvus is ready!")
            return True
        except Exception as e:
            print(f"  Attempt {i+1}/{max_retries}: Milvus not ready yet...")
            time.sleep(delay)
    raise Exception("Milvus did not become ready in time")


def create_collection():
    """Create the Milvus collection with proper schema."""
    # Check if collection exists
    if utility.has_collection(COLLECTION_NAME):
        print(f"  ⚠ Collection '{COLLECTION_NAME}' exists, dropping...")
        utility.drop_collection(COLLECTION_NAME)
    
    # Define schema
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
        FieldSchema(name="order_id", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIM),
    ]
    
    schema = CollectionSchema(
        fields=fields,
        description="Order embeddings for semantic search"
    )
    
    # Create collection
    collection = Collection(name=COLLECTION_NAME, schema=schema)
    print(f"✓ Created collection '{COLLECTION_NAME}'")
    
    return collection


def create_index(collection: Collection):
    """Create vector index for fast similarity search."""
    index_params = {
        "metric_type": "COSINE",  # or "L2", "IP"
        "index_type": "IVF_FLAT",  # Good for small-medium datasets
        "params": {"nlist": 128}
    }
    
    collection.create_index(
        field_name="embedding",
        index_params=index_params
    )
    print("✓ Created vector index (IVF_FLAT, COSINE)")


def load_vectors_from_minio(s3_client) -> pd.DataFrame:
    """Load vector data from MinIO Parquet file."""
    print("\nReading vectors from MinIO...")
    
    try:
        obj = s3_client.get_object(Bucket=BUCKET_NAME, Key=VECTORS_PATH)
        df = pd.read_parquet(io.BytesIO(obj['Body'].read()))
        print(f"  ✓ Loaded {len(df)} vectors")
        return df
    except Exception as e:
        raise ValueError(f"Failed to read vectors: {e}. Run generate_embeddings.py first.")


def insert_vectors(collection: Collection, df: pd.DataFrame):
    """Insert vectors into Milvus collection."""
    print("\nInserting vectors into Milvus...")
    
    # Prepare data for insertion
    ids = df['id'].tolist()
    order_ids = df['order_id'].tolist()
    
    # Convert embeddings from stored format
    embeddings = df['vector'].tolist()
    # Handle case where embeddings might be stored as strings or lists
    if embeddings and isinstance(embeddings[0], str):
        import ast
        embeddings = [ast.literal_eval(e) for e in embeddings]
    
    # Insert in batches
    batch_size = 100
    total_inserted = 0
    
    for i in range(0, len(ids), batch_size):
        batch_ids = ids[i:i + batch_size]
        batch_order_ids = order_ids[i:i + batch_size]
        batch_embeddings = embeddings[i:i + batch_size]
        
        data = [batch_ids, batch_order_ids, batch_embeddings]
        collection.insert(data)
        total_inserted += len(batch_ids)
        
        if total_inserted % 200 == 0 or total_inserted == len(ids):
            print(f"  ✓ Inserted {total_inserted}/{len(ids)} vectors")
    
    # Flush to ensure data is persisted
    collection.flush()
    print(f"✓ Flushed {total_inserted} vectors to storage")


def test_search(collection: Collection):
    """Run a test search to verify the collection works."""
    print("\nTesting vector search...")
    
    # Load collection into memory for search
    collection.load()
    
    # Create a random query vector
    import random
    query_vector = [[random.random() for _ in range(EMBEDDING_DIM)]]
    
    # Search
    search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}
    
    results = collection.search(
        data=query_vector,
        anns_field="embedding",
        param=search_params,
        limit=5,
        output_fields=["order_id"]
    )
    
    print("  ✓ Test search completed")
    print("\n  Top 5 results (random query):")
    for i, hit in enumerate(results[0]):
        print(f"    {i+1}. {hit.entity.get('order_id')} (score: {hit.distance:.4f})")


def main():
    print("=" * 60)
    print("Milvus Vector Loading")
    print("=" * 60)
    
    # Wait for and connect to Milvus
    wait_for_milvus()
    
    # Create collection
    print("\nSetting up Milvus collection...")
    collection = create_collection()
    
    # Load vectors from MinIO
    s3_client = create_s3_client()
    df_vectors = load_vectors_from_minio(s3_client)
    
    # Insert vectors
    insert_vectors(collection, df_vectors)
    
    # Create index
    print("\nCreating vector index...")
    create_index(collection)
    
    # Test search
    test_search(collection)
    
    print("\n" + "=" * 60)
    print("✓ Milvus loading complete!")
    print("=" * 60)
    print(f"\nCollection: {COLLECTION_NAME}")
    print(f"Vectors indexed: {collection.num_entities}")
    print(f"Embedding dimension: {EMBEDDING_DIM}")
    print(f"\nMilvus endpoint: {MILVUS_HOST}:{MILVUS_PORT}")


if __name__ == "__main__":
    main()
